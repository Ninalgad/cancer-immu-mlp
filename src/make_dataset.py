import numpy as np
import scanpy as sc
import tensorflow as tf
from sklearn.decomposition import PCA

LABEL_ENCODING = {
    'progenitor': 0,
    'effector': 1,
    'terminal exhausted': 2,
    'cycling': 3,
    'other': 4
}
GENE_IDX = [28, 35, 50, 82, 106, 180, 183, 197, 213, 236, 243, 319, 455, 528,
            618, 666, 683, 749, 819, 839, 876, 1006, 1045, 1116, 1143, 1159, 1163, 1216,
            1230, 1319, 1323, 1328, 1338, 1408, 1438, 1448, 1449, 1465, 1531, 1550, 1566,
            1619, 1626, 1683, 1710, 1723, 1774, 1887, 1941, 1946, 2012, 2037, 2083, 2145,
            2197, 2207, 2211, 2271, 2297, 2305, 2516, 2526, 2598, 2613, 2702, 2792, 2892,
            2932, 2961, 3037, 3040, 3062, 3070, 3099, 3100, 3116, 3151, 3165, 3187, 3189,
            3254, 3267, 3282, 3303, 3332, 3374, 3439, 3476, 3567, 3594, 3655, 3705, 3774,
            3804, 3805, 3968, 3982, 4017, 4085, 4091, 4096, 4105, 4132, 4149, 4188, 4204,
            4228, 4237, 4263, 4339, 4370, 4443, 4485, 4504, 4509, 4528, 4608, 4693, 4739,
            4791, 4831, 4881, 4978, 5076, 5087, 5229, 5238, 5261, 5303, 5345, 5412, 5470,
            5478, 5559, 5645, 5676, 5677, 5704, 5710, 5809, 5824, 5830, 5840, 5894, 5919,
            5926, 5997, 6027, 6037, 6043, 6060, 6074, 6078, 6133, 6193, 6208, 6253, 6278,
            6392, 6408, 6500, 6583, 6606, 6661, 6737, 6752, 6819, 6871, 6907, 6954, 6980,
            6983, 7007, 7018, 7041, 7167, 7188, 7202, 7232, 7285, 7330, 7338, 7378, 7404,
            7438, 7439, 7450, 7451, 7456, 7479, 7559, 7576, 7652, 7665, 7690, 7745, 7768,
            7852, 7855, 7890, 7924, 7995, 8150, 8157, 8176, 8183, 8213, 8250, 8286, 8326,
            8406, 8440, 8480, 8500, 8509, 8570, 8572, 8580, 8597, 8600, 8605, 8653, 8673,
            8737, 8739, 8758, 8787, 8880, 8897, 9021, 9026, 9089, 9113, 9137, 9156, 9213,
            9249, 9307, 9322, 9336, 9415, 9427, 9430, 9438, 9449, 9457, 9495, 9506, 9515,
            9541, 9581, 9591, 9603, 9626, 9647, 9702, 9793, 9859, 9935, 9960, 9966, 9988,
            10050, 10169, 10234, 10291, 10337, 10439, 10453, 10492, 10563, 10675, 10770,
            10775, 10854, 10855, 10870, 10912, 10955, 10967, 11011, 11112, 11117, 11223,
            11232, 11256, 11510, 11563, 11569, 11576, 11614, 11620, 11640, 11719, 11748,
            11810, 11820, 11843, 11857, 11862, 12001, 12049, 12052, 12067, 12127, 12150,
            12154, 12211, 12232, 12251, 12305, 12346, 12404, 12456, 12487, 12575, 12682,
            12684, 12693, 12709, 12762, 12767, 12783, 12884, 12885, 12887, 12898, 12913,
            12915, 13048, 13113, 13141, 13145, 13181, 13201, 13323, 13395, 13522, 13569,
            13583, 13588, 13649, 13655, 13749, 13759, 13780, 13796, 13833, 13838, 13847,
            13892, 13943, 13991, 13996, 14048, 14119, 14223, 14250, 14253, 14263, 14269,
            14344, 14358, 14377, 14422, 14423, 14442, 14471, 14533, 14544]


def process_adata(adata, g2v_embeddings):
    Q = []
    for p in adata.obs['condition']:
        p = p.lower()
        if p in g2v_embeddings:
            q = g2v_embeddings[p]
        else:
            q = np.zeros((200,), 'float32')
        Q.append(q)
    Q = np.array(Q)

    X = adata.X.toarray()
    Y = [LABEL_ENCODING[y] for y in adata.obs['state']]
    Y = tf.keras.utils.to_categorical(Y, num_classes=max(Y) + 1)
    Y = np.array(Y)

    return Q, X, Y


def make_dataset(adata_path, g2v_embeddings):
    adata = sc.read_h5ad(adata_path)
    Q, X, Y = process_adata(adata, g2v_embeddings)
    conditions = adata.obs['condition']

    # reduce the dimensionality
    pca = PCA(n_components=256)
    X = np.concatenate([pca.fit_transform(X),
                        X[:, GENE_IDX]], axis=-1)
    print("make_dataset", X.shape)
    return Q, X, Y, conditions
